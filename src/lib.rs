#[macro_use] extern crate maplit;
#[macro_use] extern crate hex_literal;
mod errors;
use prost::Message;
use crate::errors::{OrcError, OrcResult};
use std::io::{Read, Seek, SeekFrom, Cursor};
use std::collections::HashMap;

/// Autogenerated messages from the ORC reference implementation's `protobuf` definition
pub mod messages {
    include!(concat!(env!("OUT_DIR"), "/orc.proto.rs"));
}

pub(crate) mod codecs {
    use std::ops::Range;
    use crate::errors::{OrcError, OrcResult};
    /// Boolean run length encoding
    #[derive(Debug, Eq, PartialEq)]
    pub struct BooleanRLE(pub Range<u64>);
    /// One-byte signed integer run length encoding
    #[derive(Debug, Eq, PartialEq)]
    pub struct ByteRLE(pub Range<u64>);
    /// Variable width signed integer run length encoding
    #[derive(Debug, Eq, PartialEq)]
    pub enum IntRLE {
        V1(Range<u64>),
        V2(Range<u64>)
    }
    /// Variable width unsigned integer run length encoding
    #[derive(Debug, Eq, PartialEq)]
    pub enum UintRLE {
        V1(Range<u64>),
        V2(Range<u64>)
    }
    /// IEEE754 Float encoding
    #[derive(Debug, Eq, PartialEq)]
    pub struct FloatEnc(pub Range<u64>);
    /// Literal byte sequence without any encoding
    #[derive(Debug, Eq, PartialEq)]
    pub struct BinaryEnc(pub Range<u64>);
    /// Timestamp nanosecond encoding (handles trailing zeros specially)
    #[derive(Debug, Eq, PartialEq)]
    pub enum NanosEnc{
        V1(Range<u64>),
        V2(Range<u64>)
    }

    /// Decode a signed varint128 from a slice
    ///
    /// ORC uses the packed-varint128 structure protobuf2/3 uses
    /// but it leaves out the tag prefix so it's not compatible. :/
    /// So we use this shim to decode it instead.
    ///
    /// Returns the number and the remaining bytes.
    pub fn read_i128(buf: &[u8]) -> OrcResult<(i128, &[u8])> {
        let (value, rest) = read_u128(buf)?;
        // Inverse of (n << 1) ^ (n >> 127)
        let zigzag = (value << 127 >> 127) ^ (value >> 1);
        Ok((zigzag as i128, rest))
    }

    /// Decode an unsigned varint128 from a slice
    ///
    /// ORC uses the packed-varint128 structure protobuf2/3 uses
    /// but it leaves out the tag prefix so it's not compatible. :/
    /// So we use this shim to decode it instead.
    ///
    /// Returns the number and the remaining bytes.
    pub fn read_u128(buf: &[u8]) -> OrcResult<(u128, &[u8])> {
        let mut value = 0;
        for i in 0..buf.len() {
            value |= ((buf[i] & 0x7F) << (8*i)) as u128;
            if buf[i] & 0x80 == 0 {
                return Ok((value, &buf[i..]))
            }
        }
        Err(OrcError::TruncatedError)
    }
}

/// A handle on an open ORC file
///
/// This object holds a reference to the remainder of the file,
/// because it has at this point only deserialized the table of contents.
/// Reading a stripe will incur further IO and hence can fail.
#[derive(Debug, Clone)]
pub struct ORCFile<F: Read+Seek> {
    schema: Vec<(String, ColumnSpec)>,
    flat_schema: Vec<ColumnSpec>,
    metadata: messages::Metadata,
    footer: messages::Footer,
    postscript: messages::PostScript,
    file: F
}

impl<F: Read+Seek> ORCFile<F> {
    /// Read a compressed message from the ORC file
    ///
    /// Start and end are relative to the beginning of the file.
    fn read_message<M: Message+Default>(&mut self, start: u64, end: u64) -> OrcResult<M> {
        // Read the compressed data from the file first
        self.file.seek(SeekFrom::Start(start as u64))?;
        let mut comp_buffer_back = vec![0u8; (end-start) as usize];
        self.file.read_exact(&mut comp_buffer_back)?;
        let mut comp_buffer = &comp_buffer_back[..];

        // Start decompressing
        let mut decomp_buffer= vec![];
        while comp_buffer.len() >= 4 {
            let (chunk_len, is_compressed) = match self.postscript.compression() {
                // Messages without compression have no header
                messages::CompressionKind::None => (0, false),
                _ => {
                    let enc = [comp_buffer[0], comp_buffer[1], comp_buffer[2], 0];
                    let enc_len = u32::from_le_bytes(enc);
                    ((enc_len / 2) as usize, (enc_len & 1 == 0))
                }
            };
            match (is_compressed, self.postscript.compression()) {
                (false, messages::CompressionKind::None) => {
                    // Messages without compression have no header
                    decomp_buffer.extend_from_slice(&comp_buffer);
                }
                (false, _) => {
                    // Messages with compression, but where this block is uncompressed still have a header
                    decomp_buffer.extend_from_slice(&comp_buffer[3..chunk_len+3]);
                }
                (true, messages::CompressionKind::Zlib) => {
                    let mut decoder = flate2::read::DeflateDecoder::new(&comp_buffer[3..chunk_len+3]);
                    decoder.read_to_end(&mut decomp_buffer)?;
                }
                (true, messages::CompressionKind::Snappy) => {
                    let mut decoder = snap::read::FrameDecoder::new(&comp_buffer[3..chunk_len+3]);
                    decoder.read_to_end(&mut decomp_buffer)?;
                }
                _ => todo!("Only Zlib and Snappy compression are supported yet.")
                // Lzo = 3,
                // Lz4 = 4,
                // Zstd = 5,
            };
            comp_buffer = &comp_buffer[chunk_len+3..];
        }
        let (chunk_len, is_compressed) = match self.postscript.compression() {
            messages::CompressionKind::None => (0, false),
            _ => {
                let enc = [comp_buffer[0], comp_buffer[1], comp_buffer[2], 0];
                let enc_len = u32::from_le_bytes(enc);
                ((enc_len / 2) as usize, (enc_len & 1 == 0))
            }
        };
        let decomp_slice = match (is_compressed, self.postscript.compression()) {
            (false, _) => {
                &comp_buffer[3..]
            }
            (_, messages::CompressionKind::Zlib) => {
                let mut decoder = flate2::read::DeflateDecoder::new(&comp_buffer[3..chunk_len+3]);
                decoder.read_to_end(&mut decomp_buffer)?;
                &decomp_buffer[..]
            }
            (_, messages::CompressionKind::Snappy) => {
                let mut decoder = snap::read::FrameDecoder::new(&comp_buffer[3..chunk_len+3]);
                decoder.read_to_end(&mut decomp_buffer)?;
                &decomp_buffer[..]
            }
            _ => todo!("Only Zlib and Snappy compression is supported yet.")
            // Lzo = 3,
            // Lz4 = 4,
            // Zstd = 5,
        };
        Ok(M::decode(decomp_slice)?)
    }

    /// Read the table of contents from something readable and seekable and keep the reader
    ///
    /// It isn't finished at this point; more deserializing will be done when you read a stripe.
    /// You can pass a byte vector or a file, but streaming isn't possible because the table of contents
    /// is at the end of the file.
    pub fn from_reader(mut file: F) -> OrcResult<ORCFile<F>> {
        let file_len = file.seek(SeekFrom::End(0))?;
        let buffer_len = file_len.min(275);
        if buffer_len == 0 {
            return Err(OrcError::TruncatedError)
        }
        file.seek(SeekFrom::End(-(buffer_len as i64)))?;
        let mut buffer = vec![0u8; buffer_len as usize];
        file.read_exact(&mut buffer)?;

        // Deserialize the postscript first to get the lengths of the metadata and footer
        let postscript = read_postscript(&buffer[..])?;
        let mut me = ORCFile {
            schema: vec![],
            flat_schema: vec![],
            file,
            postscript,
            // read_message wants an ORCFile, but we need read_message to create the members
            // This is fine because these messages have defaults we can overwrite
            metadata: messages::Metadata::default(),
            footer: messages::Footer::default()
        };
        // The file ends with the metadata, footer, postacript, and one last byte for the postscript length
        let postscript_start = file_len - *buffer.last().unwrap() as u64 - 1;
        let footer_start = postscript_start - me.postscript.footer_length();
        let metadata_start = footer_start - me.postscript.metadata_length();
        
        me.footer = me.read_message::<messages::Footer>(footer_start, postscript_start)?;
        me.metadata = me.read_message::<messages::Metadata>(metadata_start, footer_start)?;
        let (schema, flat_schema) = me.read_schema(&me.footer.types)?;
        me.schema = schema;
        me.flat_schema = flat_schema;
        Ok(me)
    }

    /// Unstructured user-defined metadata about this ORC file
    ///
    /// Metadata is usually tiny, and often missing altogether. This may be empty.
    pub fn user_metadata(&self) -> HashMap<String, Vec<u8>> {
        self.footer.metadata.iter()
            .map(|kv| (kv.name().to_string(), kv.value().to_vec()))
            .collect()
    }

    /// Deserialize the schema into a tree, and also keep all columns by ID
    ///
    /// Returns a tuple, containing:
    /// * the top level columns in order as a vector with names
    /// * all columns in the order they were stored (preorder by spec)
    fn read_schema(&self, raw_types: &[messages::Type]) -> OrcResult<(Vec<(String, ColumnSpec)>, Vec<ColumnSpec>)> {
        // These are the types not yet claimed as children of another type.
        // At the end of the traversal, these are the roots of the type trees,
        // and are the types of each column, in order
        let mut roots = vec![];
        let mut all = vec![];

        // Pop consumes the last tree off the roots stack
        // It's helpful because it gives a sensible error instead or panicing if there are no roots
        // It can't own the roots vector because then we couldn't also push to it.
        // All the places we need it will also need to be Boxed to avoid making ColumnSpec infinitely recursive.
        let pop = |t: &mut Vec<ColumnSpec>| t.pop()
            .ok_or(OrcError::SchemaError("Missing child type"))
            .map(|x| Box::new(x));

        // The types are given in pre-order,
        // and for lack of imagination we iterate the types in reverse order to create the trees bottom-up.
        // Any unclaimed trees are top-level columns.
        for (id, raw_type) in raw_types.iter().enumerate().rev() {
            // This import helps reduce the noise
            use messages::r#type::Kind;
            let next_type = match raw_type.kind() {
                Kind::Boolean => ColumnSpec::Boolean{id},
                Kind::Byte => ColumnSpec::Byte{id},
                Kind::Short => ColumnSpec::Short{id},
                Kind::Int => ColumnSpec::Int{id},
                Kind::Long => ColumnSpec::Long{id},
                Kind::Float => ColumnSpec::Float{id},
                Kind::Double => ColumnSpec::Double{id},
                Kind::String => ColumnSpec::String{id},
                Kind::Binary => ColumnSpec::Binary{id},
                Kind::Timestamp
                | Kind::TimestampInstant => ColumnSpec::Timestamp{id},
                Kind::List => ColumnSpec::List{id, inner: pop(&mut roots)?},
                Kind::Map => {
                    // Undo reverse subtype order
                    let (value, key) = (pop(&mut roots)?, pop(&mut roots)?);
                    ColumnSpec::Map{id, key, value}
                },
                Kind::Struct => {
                    if raw_type.field_names.len() != raw_type.subtypes.len() {
                        return Err(OrcError::SchemaError("Field names don't match field types in struct"))
                    }
                    // Keep in mind these subtypes will be in reverse order, note rev() before zip()
                    let subtypes = roots.split_off(roots.len()-raw_type.subtypes.len());
                    // We already own the subtypes but we have to clone the field names
                    let fields = raw_type.field_names.iter().cloned().zip(subtypes.into_iter().rev()).collect();
                    ColumnSpec::Struct{id, fields}
                },
                Kind::Union => return Err(OrcError::SchemaError("Union types are not yet supported")),
                Kind::Decimal => ColumnSpec::Decimal{
                    id,
                    precision: raw_type.precision() as usize,
                    scale: raw_type.scale() as usize
                },
                Kind::Date => ColumnSpec::Date{id},
                Kind::Varchar => ColumnSpec::Varchar{id, length: raw_type.maximum_length() as usize},
                Kind::Char => ColumnSpec::Char{id, length: raw_type.maximum_length() as usize},
            };
            roots.push(next_type.clone());
            all.push(next_type);
        }
        // The flat schema is backward at this point
        all.reverse();
        // I don't see this in the standard but Hive seems to keep everything under one root Struct
        match roots.pop() {
            Some(ColumnSpec::Struct{fields, ..}) => Ok((fields, all)),
            None => Err(OrcError::SchemaError("Top level schema is empty")),
            _ => Err(OrcError::SchemaError("Top level schema was not a struct"))
        }
    }

    /// Get a reference to the schema for this file
    ///
    /// Keep in mind that columns can be nested.
    pub fn schema(&self) -> &[(String, ColumnSpec)] {
        &self.schema
    }

    /// Get a reference to all columns and their descendants
    ///
    /// These are still trees, but in this case all subtrees are listed in the top level vector.
    /// Note that for this reason field names are not given. Not all types have field names.
    pub fn flat_schema(&self) -> &[ColumnSpec] {
        &self.flat_schema
    }

    /// Get information about one stripe in the file
    ///
    /// The stripe requires a mutable borrow because it needs to seek() the underlying reader,
    /// and it would be a mess if they shared cursors.
    /// If you need to use multiple stripes at a time, either open the file multiple times,
    /// with a new OrcFile for each one,
    /// or open an `std::io::Cursor` on an mmap of the file and clone the OrcFile at will.
    /// You can't clone an OrcFile based on std::fs::file but you can clone a mmap based OrcFile.
    pub fn stripe<'t> (&'t mut self, stripe_id: usize) -> OrcResult<Stripe<'t, F>> {
        if stripe_id < self.footer.stripes.len() {
            Stripe::new(stripe_id,self)
        } else {
            Err(OrcError::NoSuchStripe(stripe_id))
        }
    }
}

impl<'t> ORCFile<Cursor<&'t [u8]>> {
    /// Read an ORC file from a slice instead of an open file
    ///
    /// It isn't finished at this point; more deserializing will be done when you read a stripe.
    /// You can pass a byte vector or a file, but streaming isn't possible because the table of contents
    /// is at the end of the file.
    pub fn from_slice(byt: &'t [u8]) -> OrcResult<Self> {
        Self::from_reader(Cursor::new(byt))
    }
}

/// Read the PostScript, the bootstrap of the ORC
///
/// The postscript ends with a one-byte length at the end of the file.
/// You read that many bytes (plus one) from the end of the file and decode it.
/// The postscript contains the footer length, so next after this you should
/// read the whole footer to learn about the stripes.
pub(crate) fn read_postscript(byt: &[u8]) -> OrcResult<messages::PostScript> {
    match byt.last() {
        None => Err(OrcError::TruncatedError),
        Some(&length) => {
            let postscript_bytes = &byt[
                byt.len() - length as usize - 1 .. byt.len()-1];
            Ok(messages::PostScript::decode(postscript_bytes)?)
        }
    }
}

/// Table Schema
///
/// ORC has a relatively rich type system and supports nested types.
#[derive(Debug, Eq, PartialEq, Clone)]
pub enum ColumnSpec {
    Boolean {id: usize},
    Byte {id: usize},
    Short {id: usize},
    Int {id: usize},
    Long {id: usize},
    Float {id: usize},
    Double {id: usize},
    String {id: usize},
    Binary {id: usize},
    Timestamp {id: usize},
    // TODO: Why is there a second timestamp type named TimestampInstant?
    List {id: usize, inner: Box<ColumnSpec> },
    /// Maps store keys and values
    Map {id: usize, key: Box<ColumnSpec>, value: Box<ColumnSpec> },
    /// Nested structures are available, with named keys
    Struct {id: usize, fields: Vec<(String, ColumnSpec)> },
    /// Hive support for Union is spotty, and we don't support it.
    Union{id: usize},
    Decimal{
        id: usize,
        precision: usize,
        scale: usize
    },
    Date {id: usize},
    Varchar {id: usize, length: usize},
    Char {id: usize, length: usize}
}
impl ColumnSpec {
    /// Get the column ID of any type
    pub fn id(&self) -> usize {
        match self {
            Self::Boolean{id}
            | Self::Byte{id}
            | Self::Short{id}
            | Self::Int{id}
            | Self::Long{id}
            | Self::Float{id}
            | Self::Double{id}
            | Self::String{id}
            | Self::Binary{id}
            | Self::Timestamp{id}
            | Self::List{id, ..}
            | Self::Map{id, ..}
            | Self::Struct{id, ..}
            | Self::Union{id}
            | Self::Decimal{id, ..}
            | Self::Date{id}
            | Self::Varchar{id, ..}
            | Self::Char{id, ..} => *id
        }
    }
}
/// A handle to one stripe in an ORCFile.
///
/// The stripe requires a mutable borrow because it needs to seek() the underlying reader,
/// and it would be a mess if they shared cursors.
/// If you need to use multiple stripes at a time, either open the file multiple times,
/// with a new OrcFile for each one,
/// or open an `std::io::Cursor` on an mmap of the file and clone the OrcFile at will.
/// You can't clone an OrcFile based on std::fs::file but you can clone a mmap based OrcFile.
pub struct Stripe<'t, F:Read+Seek> {
    file: &'t mut ORCFile<F>,
    id: usize,
    info: messages::StripeInformation,
    footer: messages::StripeFooter
}
impl<'t, F:Read+Seek> Stripe<'t, F> {
    /// Create a stripe from StripeInformation and a StripeFooter
    ///
    /// The StripeFooter is read from the parent file
    fn new(id: usize, file: &'t mut ORCFile<F>) -> OrcResult<Self> {
        let info = file.footer.stripes[id].clone();
        let footer: messages::StripeFooter = file.read_message(
            info.offset() + info.index_length() + info.data_length(), 
            info.offset() + info.index_length() + info.data_length() + info.footer_length()
        )?;
        Ok(Stripe {id, info, footer, file})
    }

    /// Number of rows in this stripe
    pub fn number_of_rows(&self) -> u64 {
        self.info.number_of_rows()
    }

    /// Return the columns available in this stripe
    pub fn columns(&self) -> OrcResult<Vec<Column>> {
        let flat_schema = self.file.flat_schema();
        if self.footer.columns.len() != flat_schema.len() {
            return Err(OrcError::SchemaError("Stripe column definitions don't match schema"))
        }
        let mut cols = vec![];
        for id in 0..flat_schema.len() {
            cols.push(Column::new(
                &flat_schema[id], 
                &self.footer.columns[id], 
                &self.footer.streams[..])?
            );
        }
        Ok(cols)
    }

}
#[derive(Debug, Eq, PartialEq)]
pub struct Column {
    spec: ColumnSpec,
    present: Option<codecs::BooleanRLE>,
    content: TypedStream
}
impl Column {
    pub fn new(
        spec: &ColumnSpec,
        enc: &messages::ColumnEncoding,
        streams: &[messages::Stream]
    ) -> OrcResult<Column> {
        use messages::column_encoding::Kind as Ckind;
        use messages::stream::Kind as Skind;
        let range_by_kind = |sk: Skind| streams.iter()
            .scan(0u64, |cur, st| {
                // The offset of each stream is the cumulative sum of the lengths
                let start = *cur;
                *cur += st.length();
                Some((start..*cur, st))
            })
            .find(|(_, stream)| stream.column() as usize == spec.id() && stream.kind() == sk)
            .map(|(rng, _) | rng)
            .ok_or(OrcError::EncodingError(format!("Column {} missing {:?} stream", spec.id(), sk)));
        // Most colspecs need these streams, so tee them up to save writing
        let data = range_by_kind(Skind::Data);
        let len = range_by_kind(Skind::Length);

        // These integer encodings are mostly orthogonal to the types
        let int_enc = |r| match enc.kind() {
            Ckind::Direct | Ckind::Dictionary => codecs::IntRLE::V1(r),
            Ckind::DirectV2 | Ckind::DictionaryV2 => codecs::IntRLE::V2(r)
        };
        let uint_enc = |r| match enc.kind() {
            Ckind::Direct | Ckind::Dictionary => codecs::UintRLE::V1(r),
            Ckind::DirectV2 | Ckind::DictionaryV2 => codecs::UintRLE::V2(r)
        };
        let content = match spec {
            ColumnSpec::Boolean{..} => TypedStream::Boolean{data: codecs::BooleanRLE(data?)},
            ColumnSpec::Byte{..}   => TypedStream::Byte{data: codecs::ByteRLE(data?)},
            ColumnSpec::Short{..}
            | ColumnSpec::Int{..}
            | ColumnSpec::Long{..}
            | ColumnSpec::Date{..} => TypedStream::Int{data: int_enc(data?)},
            ColumnSpec::Float{..}
            | ColumnSpec::Double{..} => TypedStream::Float{data: codecs::FloatEnc(data?)},
            ColumnSpec::Decimal{..} => TypedStream::Decimal{
                data: int_enc(data?),
                scale: int_enc(range_by_kind(Skind::Secondary)?)
            },
            ColumnSpec::String{..}
            | ColumnSpec::Varchar{..}
            | ColumnSpec::Char{..}
            | ColumnSpec::Binary{..} => TypedStream::Blob{
                data: codecs::BinaryEnc(data?),
                length: uint_enc(len?)
            },
            ColumnSpec::Map{..}
            | ColumnSpec::List{..} => TypedStream::Container{length: uint_enc(len?)},
            ColumnSpec::Struct{..} => TypedStream::Struct(),
            ColumnSpec::Timestamp{..} => TypedStream::Timestamp{
                seconds: int_enc(data?),
                nanos: match enc.kind() {
                    Ckind::Direct => codecs::NanosEnc::V1(range_by_kind(Skind::Secondary)?),
                    Ckind::DirectV2 => codecs::NanosEnc::V2(range_by_kind(Skind::Secondary)?),
                    _ => return Err(OrcError::EncodingError(format!("Timestamp doesn't support dictionary encoding")))
                }
            },
            ColumnSpec::Union{..} => return Err(OrcError::SchemaError("Union types are not supported")),
        };
        Ok(Column {
            spec: spec.clone(),
            present: range_by_kind(Skind::Present)
                .map(|r| codecs::BooleanRLE(r))
                .ok(),
            content
        })
    }
}

/// Joins multiple streams to create different composite types
///
/// This is where variable length types, like strings, are handled.
#[derive(Debug, Eq, PartialEq)]
pub enum TypedStream {
    /// Boolean RLE
    Boolean {data: codecs::BooleanRLE},
    /// RLE encoding for 8-bit integers and UNIONS. Unions aren't supported.
    Byte {data: codecs::ByteRLE},
    /// `DIRECT` encoding, for all int sizes, booleans, bytes, dates.
    /// For dates, the data is the days since 1970.  
    Int {data: codecs::IntRLE},
    /// `DIRECT` encoding for floats
    Float {data: codecs::FloatEnc},
    /// `DIRECT` encoding for chars, strings, varchars, and blobs
    Blob {data: codecs::BinaryEnc, length: codecs::UintRLE},
    /// For maps and lists, the data is the length.
    Container {length: codecs::UintRLE},
    /// `DICTIONARY` encoding, only for chars, strings and varshars (not blobs)
    Dict {data: codecs::IntRLE, length: codecs::UintRLE, dict: codecs::BinaryEnc},
    /// Decimals, which store i128's with an associated scale.
    Decimal {data: codecs::IntRLE, scale: codecs::IntRLE },
    /// Timestamps, which store time since 1970, plus a second stream with nanoseconds
    Timestamp {seconds: codecs::IntRLE, nanos: codecs::NanosEnc },
    /// Structs only store if they are present. The rest is in other columns.
    Struct (),
    // Unions are not supported.
}

#[cfg(test)]
mod tests {
    use crate::messages;
    #[test]
    fn test_read_postscript() {
        let orc_bytes = include_bytes!("sample.orc");
        let ps = super::read_postscript(orc_bytes).unwrap();
        assert_eq!(ps.magic(), "ORC");
        assert_eq!(ps.footer_length(), 584);
        assert_eq!(ps.compression(), messages::CompressionKind::Zlib);
        assert_eq!(ps.compression_block_size(), 131072);
        assert_eq!(ps.writer_version(), 4);
        assert_eq!(ps.metadata_length(), 331);
        assert_eq!(ps.stripe_statistics_length(), 0);
    }

    #[test]
    fn test_read_footer() {
        use super::ColumnSpec as CS;
        let orc_bytes = include_bytes!("sample.orc");
        let orc_toc = super::ORCFile::from_slice(&orc_bytes[..]).unwrap();
        // The metadata is empty
        assert_eq!(orc_toc.user_metadata(), hashmap!{});
        // This is a bit verbose but the point is to stress test the type system
        assert_eq!(orc_toc.schema(), &[
            ("_col0".into(), CS::Boolean { id: 1 }),
            ("_col1".into(), CS::Byte { id: 2 }),
            ("_col2".into(), CS::Short { id: 3 }),
            ("_col3".into(), CS::Int { id: 4 }),
            ("_col4".into(), CS::Long { id: 5 }),
            ("_col5".into(), CS::Float { id: 6 }),
            ("_col6".into(), CS::Double { id: 7 }),
            ("_col7".into(), CS::Decimal { id: 8, precision: 10, scale: 0 }),
            ("_col8".into(), CS::Char { id: 9, length: 1 }),
            ("_col9".into(), CS::Char { id: 10, length: 3 }),
            ("_col10".into(), CS::String { id: 11 }),
            ("_col11".into(), CS::Varchar { id: 12, length: 10 }),
            ("_col12".into(), CS::Binary { id: 13 }),
            ("_col13".into(), CS::Binary { id: 14 }),
            ("_col14".into(), CS::Date { id: 15 }),
            ("_col15".into(), CS::Timestamp { id: 16 }),
            ("_col16".into(), CS::List { id: 17, inner: Box::new(CS::Int { id: 18 }) }),
            ("_col17".into(), CS::List { id: 19, inner: Box::new(CS::List { id: 20, inner: Box::new(CS::Int { id: 21 }) }) }),
            ("_col18".into(), CS::Struct { id: 22, fields: vec![
                ("city".into(), CS::String { id: 23 }),
                ("population".into(), CS::Int { id: 24 })
            ] }),
            ("_col19".into(), CS::Struct { id: 25, fields: vec![
                ("city".into(), CS::Struct { id: 26, fields: vec![
                    ("name".into(), CS::String { id: 27 }),
                    ("population".into(), CS::Int { id: 28 })
                ] }),
                ("state".into(), CS::String { id: 29 })
            ] }),
            ("_col20".into(), CS::List { id: 30, inner: Box::new(CS::Struct { id: 31, fields: vec![
                ("city".into(), CS::String { id: 32 }),
                ("population".into(), CS::Int { id: 33 })
            ] }) }),
            ("_col21".into(), CS::Struct { id: 34, fields: vec![
                ("city".into(), CS::List { id: 35, inner: Box::new(CS::String { id: 36 }) }),
                ("population".into(), CS::List { id: 37, inner: Box::new(CS::Int { id: 38 }) })
            ] }),
            ("_col22".into(), CS::Map {
                id: 39,
                key: Box::new(CS::Int { id: 41 }),
                value: Box::new(CS::String { id: 40 })
            }),
            ("_col23".into(), CS::Map {
                id: 42,
                key: Box::new(CS::Map {
                    id: 44,
                    key: Box::new(CS::Int { id: 46 }),
                    value: Box::new(CS::String { id: 45 })
                }),
                value: Box::new(CS::String { id: 43 })
            })
        ]);
    }

    #[test]
    fn test_stripe() {
        use super::Column;
        use super::codecs::*;
        use super::TypedStream as TS;
        use super::ColumnSpec as CS;
        let orc_bytes = include_bytes!("sample.orc");
        let mut orc_toc = super::ORCFile::from_slice(&orc_bytes[..]).unwrap();
        let specs = orc_toc.flat_schema().to_vec();
        let stripe = orc_toc.stripe(0).unwrap();
        assert_eq!(stripe.number_of_rows(), 3);
        assert_eq!(stripe.columns().unwrap(), vec![
            Column { spec: specs[0].clone(), present: None, content: TS::Struct() },
            Column { spec: specs[1].clone(), present: Some(BooleanRLE(1149..1154)), content: TS::Boolean { data: BooleanRLE(1154..1159) } },
            Column { spec: specs[2].clone(), present: Some(BooleanRLE(1159..1164)), content: TS::Byte { data: ByteRLE(1164..1170) } },
            Column { spec: specs[3].clone(), present: Some(BooleanRLE(1170..1175)), content: TS::Int { data: IntRLE::V2(1175..1182) } },
            Column { spec: specs[4].clone(), present: Some(BooleanRLE(1182..1187)), content: TS::Int { data: IntRLE::V2(1187..1194) } },
            Column { spec: specs[5].clone(), present: Some(BooleanRLE(1194..1199)), content: TS::Int { data: IntRLE::V2(1199..1206) } },
            Column { spec: specs[6].clone(), present: Some(BooleanRLE(1206..1211)), content: TS::Float { data: FloatEnc(1211..1222) } },
            Column { spec: specs[7].clone(), present: Some(BooleanRLE(1222..1227)), content: TS::Float { data: FloatEnc(1227..1242) } },
            Column { spec: specs[8].clone(), present: Some(BooleanRLE(1242..1247)), content: TS::Decimal { data: IntRLE::V2(1247..1252), scale: IntRLE::V2(1252..1258) } },
            Column { spec: specs[9].clone(), present: Some(BooleanRLE(1258..1263)), content: TS::Blob { data: BinaryEnc(1263..1268), length: UintRLE::V2(1268..1274) } },
            Column { spec: specs[10].clone(), present: Some(BooleanRLE(1274..1279)), content: TS::Blob { data: BinaryEnc(1279..1288), length: UintRLE::V2(1288..1294) } },
            Column { spec: specs[11].clone(), present: Some(BooleanRLE(1294..1299)), content: TS::Blob { data: BinaryEnc(1299..1305), length: UintRLE::V2(1305..1311) } },
            Column { spec: specs[12].clone(), present: Some(BooleanRLE(1311..1316)), content: TS::Blob { data: BinaryEnc(1316..1322), length: UintRLE::V2(1322..1328) } },
            Column { spec: specs[13].clone(), present: Some(BooleanRLE(1328..1333)), content: TS::Blob { data: BinaryEnc(1333..1339), length: UintRLE::V2(1339..1345) } },
            Column { spec: specs[14].clone(), present: Some(BooleanRLE(1345..1350)), content: TS::Blob { data: BinaryEnc(1350..1358), length: UintRLE::V2(1358..1364) } },
            Column { spec: specs[15].clone(), present: Some(BooleanRLE(1364..1369)), content: TS::Int { data: IntRLE::V2(1369..1380) } },
            Column { spec: specs[16].clone(), present: Some(BooleanRLE(1380..1385)), content: TS::Timestamp { seconds: IntRLE::V2(1385..1398), nanos: NanosEnc::V2(1398..1407) } },
            Column { spec: specs[17].clone(), present: None, content: TS::Container { length: UintRLE::V2(1407..1412) } },
            Column { spec: specs[18].clone(), present: Some(BooleanRLE(1412..1418)), content: TS::Int { data: IntRLE::V2(1418..1428) } },
            Column { spec: specs[19].clone(), present: None, content: TS::Container { length: UintRLE::V2(1428..1433) } },
            Column { spec: specs[20].clone(), present: None, content: TS::Container { length: UintRLE::V2(1433..1438) } },
            Column { spec: specs[21].clone(), present: Some(BooleanRLE(1438..1444)), content: TS::Int { data: IntRLE::V2(1444..1454) } },
            Column { spec: specs[22].clone(), present: None, content: TS::Struct() },
            Column { spec: specs[23].clone(), present: None, content: TS::Blob { data: BinaryEnc(1454..1459), length: UintRLE::V2(1459..1465) } },
            Column { spec: specs[24].clone(), present: Some(BooleanRLE(1479..1484)), content: TS::Int { data: IntRLE::V2(1484..1491) } },
            Column { spec: specs[25].clone(), present: None, content: TS::Struct() },
            Column { spec: specs[26].clone(), present: None, content: TS::Struct() },
            Column { spec: specs[27].clone(), present: None, content: TS::Blob { data: BinaryEnc(1491..1496), length: UintRLE::V2(1496..1502) } },
            Column { spec: specs[28].clone(), present: Some(BooleanRLE(1516..1521)), content: TS::Int { data: IntRLE::V2(1521..1528) } },
            Column { spec: specs[29].clone(), present: None, content: TS::Blob { data: BinaryEnc(1528..1533), length: UintRLE::V2(1533..1539) } },
            Column { spec: specs[30].clone(), present: None, content: TS::Container { length: UintRLE::V2(1544..1549) } },
            Column { spec: specs[31].clone(), present: None, content: TS::Struct() },
            Column { spec: specs[32].clone(), present: None, content: TS::Blob { data: BinaryEnc(1549..1555), length: UintRLE::V2(1555..1561) } },
            Column { spec: specs[33].clone(), present: Some(BooleanRLE(1582..1587)), content: TS::Int { data: IntRLE::V2(1587..1600) } },
            Column { spec: specs[34].clone(), present: None, content: TS::Struct() },
            Column { spec: specs[35].clone(), present: None, content: TS::Container { length: UintRLE::V2(1600..1605) } },
            Column { spec: specs[36].clone(), present: None, content: TS::Blob { data: BinaryEnc(1605..1611), length: UintRLE::V2(1611..1617) } },
            Column { spec: specs[37].clone(), present: None, content: TS::Container { length: UintRLE::V2(1638..1643) } },
            Column { spec: specs[38].clone(), present: Some(BooleanRLE(1643..1648)), content: TS::Int { data: IntRLE::V2(1648..1661) } },
            Column { spec: specs[39].clone(), present: None, content: TS::Container { length: UintRLE::V2(1661..1666) } },
            Column { spec: specs[40].clone(), present: None, content: TS::Blob { data: BinaryEnc(1666..1672), length: UintRLE::V2(1672..1678) } },
            Column { spec: specs[41].clone(), present: Some(BooleanRLE(1690..1695)), content: TS::Int { data: IntRLE::V2(1695..1708) } },
            Column { spec: specs[42].clone(), present: None, content: TS::Container { length: UintRLE::V2(1708..1713) } },
            Column { spec: specs[43].clone(), present: None, content: TS::Blob { data: BinaryEnc(1713..1718), length: UintRLE::V2(1718..1724) } },
            Column { spec: specs[44].clone(), present: None, content: TS::Container { length: UintRLE::V2(1731..1736) } },
            Column { spec: specs[45].clone(), present: None, content: TS::Blob { data: BinaryEnc(1736..1741), length: UintRLE::V2(1741..1747) } },
            Column { spec: specs[46].clone(), present: Some(BooleanRLE(1755..1760)), content: TS::Int { data: IntRLE::V2(1760..1769) } }
        ]);
    }
}
